{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# UDS Data Cleaning and Preparation\n",
    "\n",
    "This notebook extracts the C1/C2 Neuropsych Battery variable catalog from the UDS PDF,\n",
    "aligns the investigator CSV to those variables, and prepares analysis-ready subsets.\n",
    "\n",
    "Outputs saved to the configured output directory include:\n",
    "- `variable_catalog.csv`\n",
    "- `cleaned_subset.parquet` (only catalog variables)\n",
    "- `availability_summary.csv` (column-wise non-missing counts)\n",
    "- `stats.txt` (empty-rows summary)\n",
    "- Optional: `availability_heatmap.png`\n",
    "- `mmse_only.parquet`, `moca_only.parquet` (mutually exclusive subsets)\n",
    "\n",
    "Requirements: `pandas`, `pdfplumber`, `matplotlib`, `seaborn` (for optional heatmap).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "CSV_PATH = '../../data-files/investigator_nacc67.csv'\n",
    "PDF_PATH = '../../data-files/rdd_uds.pdf'\n",
    "PAGE_RANGE = (23, 27)  # inclusive zero-based pages for C1/C2 tables\n",
    "OUT_DIR = '../../outputs/uds_extraction'\n",
    "MMSE_COLS = ['NACCMMSE']  # extend if needed\n",
    "MOCA_COLS = ['NACCMOCA']  # extend if needed\n",
    "PLOT_HEATMAP = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Add the project root to sys.path so we can import from 'src'\n",
    "project_root = next((p for p in [Path.cwd()] + list(Path.cwd().parents) if (p / 'src').exists()), None)\n",
    "if project_root and str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src.data.uds_extraction import (\n",
    "    build_variable_catalog,\n",
    "    load_nacc_csv,\n",
    "    align_dataset_to_catalog,\n",
    "    compute_empty_rows_mask,\n",
    "    plot_availability_heatmap,\n",
    ")\n",
    "\n",
    "out_dir = Path(OUT_DIR)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_dir.as_posix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Build variable catalog from PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = build_variable_catalog(PDF_PATH, PAGE_RANGE)\n",
    "catalog_path = out_dir / 'variable_catalog.csv'\n",
    "catalog.to_csv(catalog_path, index=False)\n",
    "catalog.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Load CSV and align to catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_nacc_csv(CSV_PATH)\n",
    "cleaned, availability = align_dataset_to_catalog(\n",
    "    df, catalog, mmse_cols=MMSE_COLS, moca_cols=MOCA_COLS\n",
    ")\n",
    "cleaned_path = out_dir / 'cleaned_subset.parquet'\n",
    "availability_path = out_dir / 'availability_summary.csv'\n",
    "\n",
    "# Fix for pyarrow compatibility:\n",
    "# 1. Convert to best possible types\n",
    "cleaned = cleaned.convert_dtypes()\n",
    "\n",
    "# 2. Convert any remaining object columns to string, handling all edge cases\n",
    "for col in cleaned.columns:\n",
    "    if cleaned[col].dtype == 'object' or str(cleaned[col].dtype) == 'object':\n",
    "        cleaned[col] = cleaned[col].astype(\"string\")\n",
    "\n",
    "# 3. Save with engine specification to handle nullable types properly\n",
    "cleaned.to_parquet(cleaned_path, index=False, engine='pyarrow')\n",
    "availability.to_csv(availability_path, index=False)\n",
    "cleaned.shape, availability.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_mask = compute_empty_rows_mask(cleaned)\n",
    "stats_txt = (\n",
    "    f'Rows total: {len(cleaned)}\\n'\n",
    "    f'Completely empty (all -4/NaN): {int(empty_mask.sum())}\\n'\n",
    "    f'With some data: {int((~empty_mask).sum())}\\n'\n",
    ")\n",
    "(out_dir / 'stats.txt').write_text(stats_txt)\n",
    "print(stats_txt)\n",
    "if PLOT_HEATMAP:\n",
    "    plot_availability_heatmap(cleaned, out_path=str(out_dir / 'availability_heatmap.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Quick previews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cleaned)\n",
    "display(availability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Split into MMSE-only and MOCA-only (XOR) and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows where exactly one of has_MMSE / has_MOCA is True (XOR)\n",
    "xor_mask = cleaned[\"has_MMSE\"] ^ cleaned[\"has_MOCA\"]\n",
    "filtered = cleaned.loc[xor_mask].copy()\n",
    "\n",
    "# Split into two sets\n",
    "df_mmse_only = filtered.loc[filtered[\"has_MMSE\"].fillna(False)].copy()\n",
    "df_moca_only = filtered.loc[filtered[\"has_MOCA\"].fillna(False)].copy()\n",
    "\n",
    "# Save\n",
    "mmse_only_path = out_dir / 'mmse_only.parquet'\n",
    "moca_only_path = out_dir / 'moca_only.parquet'\n",
    "df_mmse_only.to_parquet(mmse_only_path, index=False)\n",
    "df_moca_only.to_parquet(moca_only_path, index=False)\n",
    "\n",
    "print(\n",
    "    f\"Saved MMSE-only rows: {len(df_mmse_only)} to {mmse_only_path}\\n\"\n",
    "    f\"Saved MOCA-only rows: {len(df_moca_only)} to {moca_only_path}\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDS Data Dictionary Exploration and Analysis\n",
    "\n",
    "This notebook investigates 472 NACC cases with neuropathological slide data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task the first\n",
    "\n",
    "Investigate neuropsych testing results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('../../data-files/investigator_nacc67.csv')\n",
    "df.head()\n",
    "\n",
    "# TODO: Extract Npsy columns for inspection\n",
    "# TODO: Discover tests given\n",
    "# TODO: Seek inter-test correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df.columns.tolist()\n",
    "print(f\"\\nNumber of columns: {len(column_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "# Open the PDF and inspect the table structure\n",
    "with pdfplumber.open(\"../../data-files/rdd_uds.pdf\") as pdf:\n",
    "    print(f\"Total pages: {len(pdf.pages)}\\n\")\n",
    "    \n",
    "    # Check first few pages for tables\n",
    "    for page_num in range(23, 28):\n",
    "        page = pdf.pages[page_num]\n",
    "        tables = page.extract_tables()\n",
    "        \n",
    "        if tables:\n",
    "            print(f\"Found {len(tables)} table(s) on page {page_num + 1}\")\n",
    "            print(f\"First few rows:\")\n",
    "            for i, row in enumerate(tables[0][:3]):\n",
    "                print(f\"  Row {i}: {row}\")\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all tables from the PDF\n",
    "all_data = []\n",
    "\n",
    "with pdfplumber.open(\"../../data-files/rdd_uds.pdf\") as pdf:\n",
    "    for page_num in range(23,28):\n",
    "        page = pdf.pages[page_num]\n",
    "        tables = page.extract_tables()\n",
    "        \n",
    "        for table in tables:\n",
    "            if table:\n",
    "                for row in table:\n",
    "                    # Skip empty rows or header rows\n",
    "                    if len(row) < 3:\n",
    "                        continue\n",
    "                    if row[2] == 'Variable name':\n",
    "                        continue\n",
    "                    \n",
    "                    # Add the row if variable name exists\n",
    "                    if row[2] and row[2].strip():\n",
    "                        all_data.append(row)\n",
    "\n",
    "print(f\"Total rows extracted: {len(all_data)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "for i in range(min(5, len(all_data))):\n",
    "    print(all_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for C1 and C2 Neuropsychological Battery\n",
    "c1_c2_data = []\n",
    "\n",
    "for row in all_data:\n",
    "    # The form field can be in column 0 or 1\n",
    "    form_field = \"\"\n",
    "    if row[0]:\n",
    "        form_field = row[0]\n",
    "    elif len(row) > 1 and row[1]:\n",
    "        form_field = row[1]\n",
    "    \n",
    "    # Check if it mentions C1 or C2 with Neuropsychological Battery\n",
    "    if form_field:\n",
    "        if ('C1' in form_field or 'C2' in form_field):\n",
    "            c1_c2_data.append(row)\n",
    "\n",
    "print(f\"Rows matching C1 or C2 Neuropsychological Battery: {len(c1_c2_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_filtered = pd.DataFrame(c1_c2_data, \n",
    "                          columns=['Form1', 'Form2', 'Variable name', \n",
    "                                  'Short descriptor', 'Variable type', 'Source'])\n",
    "\n",
    "# Display first few rows\n",
    "print(df_filtered.head(10))\n",
    "\n",
    "# Check shape\n",
    "print(f\"\\nShape: {df_filtered.shape}\")\n",
    "\n",
    "# Check for any issues\n",
    "print(f\"\\nNull values:\\n{df_filtered.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the variable names\n",
    "variable_names = df_filtered['Variable name'].tolist()\n",
    "\n",
    "print(f\"Total variables: {len(variable_names)}\")\n",
    "print(\"\\nVariable names:\")\n",
    "for var in variable_names:\n",
    "    print(f\"  - {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv('../../data-files/investigator_nacc67.csv')\n",
    "\n",
    "available_vars = [var for var in variable_names if var.lower() in [col.lower() for col in df_main.columns]]\n",
    "missing_vars = [var for var in variable_names if var.lower() not in [col.lower() for col in df_main.columns]]\n",
    "\n",
    "\n",
    "print(f'Variables available in dataset: {len(available_vars)}')\n",
    "print(f'Variables missing from dataset: {len(missing_vars)}')\n",
    "\n",
    "if missing_vars:\n",
    "    print('\\nMissing variables:')\n",
    "    for var in missing_vars:\n",
    "        print(f'  - {var}')\n",
    "        \n",
    "        \n",
    "cols_to_keep = [col for col in df_main.columns if any(col.lower() == var.lower() for var in variable_names)]\n",
    "df_filtered_main = df_main[cols_to_keep]\n",
    "\n",
    "print(f\"\\nFiltered dataset shape: {df_filtered_main.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import zip_longest\n",
    "\n",
    "# For lists of different lengths, pad with None\n",
    "dff = pd.DataFrame({\n",
    "    'available_vars': list(available_vars),\n",
    "    'cols_to_keep': list(cols_to_keep) + [None] * (len(available_vars) - len(cols_to_keep))\n",
    "})\n",
    "\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = [var for var in ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in variable_names (the list from your PDF)\n",
    "from collections import Counter\n",
    "\n",
    "# Count occurrences of each variable (case-insensitive)\n",
    "var_counts = Counter([var.lower() for var in variable_names])\n",
    "\n",
    "# Find duplicates\n",
    "duplicates = {var: count for var, count in var_counts.items() if count > 1}\n",
    "\n",
    "print(f\"Duplicate variables in your PDF extraction: {len(duplicates)}\")\n",
    "if duplicates:\n",
    "    print(\"\\nDuplicate variables:\")\n",
    "    for var, count in duplicates.items():\n",
    "        print(f\"  {var}: appears {count} times\")\n",
    "        # Show the actual different versions\n",
    "        versions = [v for v in variable_names if v.lower() == var]\n",
    "        print(f\"    Versions: {versions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the values in NACCMMSE and NACCMOCA\n",
    "print(\"NACCMMSE value counts:\")\n",
    "print(df_filtered_main['NACCMMSE'].value_counts().sort_index())\n",
    "print(f\"\\nNACCMOCA value counts:\")\n",
    "print(df_filtered_main['NACCMOCA'].value_counts().sort_index())\n",
    "\n",
    "# Create version indicators\n",
    "# UDS v2: Has MMSE data (not -4) and no MoCA data (-4)\n",
    "# UDS v3: Has MoCA data (not -4) and possibly MMSE data too\n",
    "\n",
    "df_filtered_main['has_MMSE'] = df_filtered_main['NACCMMSE'] != -4\n",
    "df_filtered_main['has_MOCA'] = df_filtered_main['NACCMOCA'] != -4\n",
    "\n",
    "# Split into groups\n",
    "v2_only = df_filtered_main[df_filtered_main['has_MMSE'] & ~df_filtered_main['has_MOCA']]\n",
    "v3_only = df_filtered_main[~df_filtered_main['has_MMSE'] & df_filtered_main['has_MOCA']]\n",
    "both = df_filtered_main[df_filtered_main['has_MMSE'] & df_filtered_main['has_MOCA']]\n",
    "neither = df_filtered_main[~df_filtered_main['has_MMSE'] & ~df_filtered_main['has_MOCA']]\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA AVAILABILITY SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total participants: {len(df_filtered_main)}\")\n",
    "print(f\"\\nUDS v2 (MMSE only): {len(v2_only)} ({len(v2_only)/len(df_filtered_main)*100:.1f}%)\")\n",
    "print(f\"UDS v3 (MoCA only): {len(v3_only)} ({len(v3_only)/len(df_filtered_main)*100:.1f}%)\")\n",
    "print(f\"Both MMSE and MoCA: {len(both)} ({len(both)/len(df_filtered_main)*100:.1f}%)\")\n",
    "print(f\"Neither test: {len(neither)} ({neither/len(df_filtered_main)*100:.1f}%)\")\n",
    "print(f\"\\nVerification: {len(v2_only) + len(v3_only) + len(both) + len(neither)} = {len(df_filtered_main)}\")\n",
    "\n",
    "# Additional analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED BREAKDOWN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Participants with ANY MMSE data: {df_filtered_main['has_MMSE'].sum()}\")\n",
    "print(f\"Participants with ANY MoCA data: {df_filtered_main['has_MOCA'].sum()}\")\n",
    "print(f\"Participants with usable data (v2 or v3): {len(v2_only) + len(v3_only) + len(both)}\")\n",
    "print(f\"Participants with NO test data: {len(neither)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create v2 dataset (participants with MMSE, exclude MoCA columns if desired)\n",
    "df_v2 = v2_only.copy()\n",
    "\n",
    "# Create v3 dataset (participants with MoCA, exclude MMSE columns if desired)\n",
    "df_v3 = v3_only.copy()\n",
    "\n",
    "# If you want to include \"both\" group, decide which version to assign them to\n",
    "# Option 1: Add \"both\" to v3 (assuming later version takes precedence)\n",
    "df_v3_with_both = pd.concat([v3_only, both], ignore_index=True)\n",
    "\n",
    "print(f\"\\nv2 dataset shape: {df_v2.shape}\")\n",
    "print(f\"v3 dataset shape: {df_v3.shape}\")\n",
    "print(f\"v3 dataset (including 'both'): {df_v3_with_both.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create bar chart\n",
    "categories = ['v2 Only\\n(MMSE)', 'v3 Only\\n(MoCA)', 'Both Tests', 'Neither']\n",
    "counts = [len(v2_only), len(v3_only), len(both), len(neither)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(categories, counts, color=['#2ecc71', '#3498db', '#f39c12', '#e74c3c'])\n",
    "plt.ylabel('Number of Participants')\n",
    "plt.title('Distribution of UDS Versions by Test Availability')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, counts):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{count}\\n({count/len(df_filtered_main)*100:.1f}%)',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a crosstab to see the relationship\n",
    "crosstab = pd.crosstab(\n",
    "    df_filtered_main['has_MMSE'], \n",
    "    df_filtered_main['has_MOCA'],\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "crosstab.index = ['No MMSE', 'Has MMSE', 'Total']\n",
    "crosstab.columns = ['No MoCA', 'Has MoCA', 'Total']\n",
    "\n",
    "print(\"\\nCrosstabulation:\")\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with just the \"neither\" group\n",
    "df_neither = neither.copy()\n",
    "\n",
    "print(f\"Total rows in 'neither' group: {len(df_neither)}\")\n",
    "print(f\"Total columns: {df_neither.shape[1]}\")\n",
    "\n",
    "# Check how much data exists in this subset\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA AVAILABILITY IN 'NEITHER' GROUP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Count non-null values for each column\n",
    "non_null_counts = df_neither.count()\n",
    "print(\"\\nColumns with ANY data (not null and not -4):\")\n",
    "\n",
    "for col in df_neither.columns:\n",
    "    # Count values that are not null AND not -4\n",
    "    valid_data = df_neither[col][(df_neither[col].notna()) & (df_neither[col] != -4)]\n",
    "    count = len(valid_data)\n",
    "    percentage = (count / len(df_neither)) * 100\n",
    "    \n",
    "    if count > 0:\n",
    "        print(f\"  {col}: {count} rows ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for completely empty rows (all values are NaN or -4)\n",
    "def is_row_empty(row):\n",
    "    # Exclude the helper columns we added (has_MMSE, has_MOCA)\n",
    "    data_cols = [col for col in row.index if col not in ['has_MMSE', 'has_MOCA']]\n",
    "    for val in row[data_cols]:\n",
    "        if pd.notna(val) and val != -4:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "completely_empty = df_neither.apply(is_row_empty, axis=1)\n",
    "\n",
    "print(f\"\\nCompletely empty rows (all -4 or NaN): {completely_empty.sum()}\")\n",
    "print(f\"Rows with at least some data: {(~completely_empty).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank columns by data availability\n",
    "data_summary = []\n",
    "\n",
    "for col in df_neither.columns:\n",
    "    if col not in ['has_MMSE', 'has_MOCA']:\n",
    "        valid_count = len(df_neither[col][(df_neither[col].notna()) & (df_neither[col] != -4)])\n",
    "        data_summary.append({\n",
    "            'Column': col,\n",
    "            'Valid_Data_Count': valid_count,\n",
    "            'Percentage': (valid_count / len(df_neither)) * 100\n",
    "        })\n",
    "\n",
    "df_summary = pd.DataFrame(data_summary).sort_values('Valid_Data_Count', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 columns with most data:\")\n",
    "print(df_summary.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\nColumns with NO valid data:\")\n",
    "no_data_cols = df_summary[df_summary['Valid_Data_Count'] == 0]['Column'].tolist()\n",
    "print(f\"Count: {len(no_data_cols)}\")\n",
    "print(no_data_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample 100 random rows for visualization (or all if less than 100)\n",
    "sample_size = min(100, len(df_neither))\n",
    "df_sample = df_neither.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Create binary matrix: 1 if valid data, 0 otherwise\n",
    "data_cols = [col for col in df_sample.columns if col not in ['has_MMSE', 'has_MOCA']]\n",
    "binary_data = df_sample[data_cols].apply(lambda x: ((x.notna()) & (x != -4)).astype(int))\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(binary_data.T, aspect='auto', cmap='RdYlGn', interpolation='nearest')\n",
    "plt.colorbar(label='Has Data (1) / No Data (0)')\n",
    "plt.xlabel('Sample Participants')\n",
    "plt.ylabel('Variables')\n",
    "plt.title(f'Data Availability Heatmap (Sample of {sample_size} participants from \"neither\" group)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOverall data density in 'neither' group: {binary_data.values.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a few sample rows with some data\n",
    "rows_with_data = df_neither[~completely_empty]\n",
    "\n",
    "if len(rows_with_data) > 0:\n",
    "    print(f\"\\nSample of rows with some data (showing first 5):\")\n",
    "    print(rows_with_data.head())\n",
    "    \n",
    "    # Show which columns have data in these sample rows\n",
    "    print(\"\\nNon-empty values in first sample row:\")\n",
    "    first_row = rows_with_data.iloc[0]\n",
    "    for col in first_row.index:\n",
    "        if col not in ['has_MMSE', 'has_MOCA'] and pd.notna(first_row[col]) and first_row[col] != -4:\n",
    "            print(f\"  {col}: {first_row[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

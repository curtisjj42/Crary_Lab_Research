{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDS Table Extraction and Dataset Cleaning (Clean Notebook)\n",
    "\n",
    "This notebook focuses on extracting the C1/C2 Neuropsych Battery variable catalog from the UDS PDF and aligning the investigator CSV to those variables.\n",
    "\n",
    "Outputs saved to the configured output directory include:\n",
    "- `variable_catalog.csv`\n",
    "- `cleaned_subset.parquet` (only catalog variables)\n",
    "- `availability_summary.csv` (column-wise non-missing counts)\n",
    "- `stats.txt` (empty-rows summary)\n",
    "- Optional: `availability_heatmap.png`\n",
    "\n",
    "Requirements: `pandas`, `pdfplumber`, `matplotlib`, `seaborn` (for optional heatmap).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:11:26.042333Z",
     "start_time": "2025-12-09T21:11:26.033853Z"
    }
   },
   "source": [
    "# Parameters\n",
    "CSV_PATH = '../../data-files/investigator_nacc67.csv'\n",
    "PDF_PATH = '../../data-files/rdd_uds.pdf'\n",
    "PAGE_RANGE = (23, 27)  # inclusive zero-based pages for C1/C2 tables\n",
    "OUT_DIR = '../../outputs/uds_extraction'\n",
    "MMSE_COLS = ['NACCMMSE']  # extend if needed\n",
    "MOCA_COLS = ['NACCMOCA']  # extend if needed\n",
    "PLOT_HEATMAP = True\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:11:26.233746Z",
     "start_time": "2025-12-09T21:11:26.073083Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Add the project root to sys.path so we can import from 'src'\n",
    "# This searches for the 'src' folder in the current directory or its parents\n",
    "project_root = next((p for p in [Path.cwd()] + list(Path.cwd().parents) if (p / 'src').exists()), None)\n",
    "if project_root and str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src.data.uds_extraction import (\n",
    "    build_variable_catalog,\n",
    "    load_nacc_csv,\n",
    "    align_dataset_to_catalog,\n",
    "    compute_empty_rows_mask,\n",
    "    plot_availability_heatmap,\n",
    ")\n",
    "\n",
    "out_dir = Path(OUT_DIR)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_dir.as_posix()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../outputs/uds_extraction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build variable catalog from PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:11:28.367396Z",
     "start_time": "2025-12-09T21:11:26.259278Z"
    }
   },
   "source": [
    "catalog = build_variable_catalog(PDF_PATH, PAGE_RANGE)\n",
    "catalog_path = out_dir / 'variable_catalog.csv'\n",
    "catalog.to_csv(catalog_path, index=False)\n",
    "catalog.head(10)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                      form_field variable_name  \\\n",
       "0                                             C1      MMSECOMP   \n",
       "1  C1 Neuropsychological Battery\\nSummary Scores       MMSELOC   \n",
       "2                                             C1       MMSELAN   \n",
       "3  C1 Neuropsychological Battery\\nSummary Scores      MMSELANX   \n",
       "4                                             C1       MMSEVIS   \n",
       "5  C1 Neuropsychological Battery\\nSummary Scores      MMSEHEAR   \n",
       "6                                             C1      MMSEORDA   \n",
       "7  C1 Neuropsychological Battery\\nSummary Scores      MMSEORLO   \n",
       "8                                             C1      PENTAGON   \n",
       "9  C1 Neuropsychological Battery\\nSummary Scores      NACCMMSE   \n",
       "\n",
       "                                               label  source_page  \n",
       "0                Was any part of the MMSE completed?           26  \n",
       "1                    Administration of the MMSE was:           27  \n",
       "2                    Language of MMSE administration           28  \n",
       "3  Language of MMSE administration —\\nOther (spec...           29  \n",
       "4  Subject was unable to complete one or\\nmore se...           30  \n",
       "5  Subject was unable to complete one or\\nmore se...           31  \n",
       "6                  Orientation subscale score — Time           32  \n",
       "7                 Orientation subscale score — Place           33  \n",
       "8               Intersecting pentagon subscale score           34  \n",
       "9                 Total MMSE score (using D-L-R-O-W)           35  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form_field</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>label</th>\n",
       "      <th>source_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1</td>\n",
       "      <td>MMSECOMP</td>\n",
       "      <td>Was any part of the MMSE completed?</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1 Neuropsychological Battery\\nSummary Scores</td>\n",
       "      <td>MMSELOC</td>\n",
       "      <td>Administration of the MMSE was:</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1</td>\n",
       "      <td>MMSELAN</td>\n",
       "      <td>Language of MMSE administration</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1 Neuropsychological Battery\\nSummary Scores</td>\n",
       "      <td>MMSELANX</td>\n",
       "      <td>Language of MMSE administration —\\nOther (spec...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1</td>\n",
       "      <td>MMSEVIS</td>\n",
       "      <td>Subject was unable to complete one or\\nmore se...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C1 Neuropsychological Battery\\nSummary Scores</td>\n",
       "      <td>MMSEHEAR</td>\n",
       "      <td>Subject was unable to complete one or\\nmore se...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C1</td>\n",
       "      <td>MMSEORDA</td>\n",
       "      <td>Orientation subscale score — Time</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C1 Neuropsychological Battery\\nSummary Scores</td>\n",
       "      <td>MMSEORLO</td>\n",
       "      <td>Orientation subscale score — Place</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C1</td>\n",
       "      <td>PENTAGON</td>\n",
       "      <td>Intersecting pentagon subscale score</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C1 Neuropsychological Battery\\nSummary Scores</td>\n",
       "      <td>NACCMMSE</td>\n",
       "      <td>Total MMSE score (using D-L-R-O-W)</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV and align to catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:12:52.356082Z",
     "start_time": "2025-12-09T21:11:29.044466Z"
    }
   },
   "source": "df = load_nacc_csv(CSV_PATH)\ncleaned, availability = align_dataset_to_catalog(\n    df, catalog, mmse_cols=MMSE_COLS, moca_cols=MOCA_COLS\n)\ncleaned_path = out_dir / 'cleaned_subset.parquet'\navailability_path = out_dir / 'availability_summary.csv'\n\n# Fix for pyarrow compatibility:\n# 1. Convert to best possible types\ncleaned = cleaned.convert_dtypes()\n\n# 2. Convert any remaining object columns to string, handling all edge cases\nfor col in cleaned.columns:\n    if cleaned[col].dtype == 'object' or str(cleaned[col].dtype) == 'object':\n        cleaned[col] = cleaned[col].astype(\"string\")\n\n# 3. Save with engine specification to handle nullable types properly\ncleaned.to_parquet(cleaned_path, index=False, engine='pyarrow')\navailability.to_csv(availability_path, index=False)\ncleaned.shape, availability.shape",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\curti\\PycharmProjects\\Crary_Lab_Research\\src\\data\\uds_extraction.py:226: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((195196, 98), (96, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:14:25.562672Z",
     "start_time": "2025-12-09T21:12:52.465360Z"
    }
   },
   "source": [
    "empty_mask = compute_empty_rows_mask(cleaned)\n",
    "stats_txt = (\n",
    "    f'Rows total: {len(cleaned)}\\n'\n",
    "    f'Completely empty (all -4/NaN): {int(empty_mask.sum())}\\n'\n",
    "    f'With some data: {int((~empty_mask).sum())}\\n'\n",
    ")\n",
    "(out_dir / 'stats.txt').write_text(stats_txt)\n",
    "print(stats_txt)\n",
    "if PLOT_HEATMAP:\n",
    "    plot_availability_heatmap(cleaned, out_path=str(out_dir / 'availability_heatmap.png'))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows total: 195196\n",
      "Completely empty (all -4/NaN): 0\n",
      "With some data: 195196\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick previews\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:14:25.753973Z",
     "start_time": "2025-12-09T21:14:25.664168Z"
    }
   },
   "source": [
    "display(cleaned)\n",
    "display(availability)\n",
    "# End of notebook\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        MMSECOMP  MMSELOC  MMSELAN MMSELANX  MMSEVIS  MMSEHEAR  MMSEORDA  \\\n",
       "0             -4       -4       -4     <NA>       -4        -4        -4   \n",
       "1             -4       -4       -4     <NA>       -4        -4        -4   \n",
       "2             -4       -4       -4     <NA>       -4        -4        -4   \n",
       "3             -4       -4       -4     <NA>       -4        -4        -4   \n",
       "4             -4       -4       -4     <NA>       -4        -4        -4   \n",
       "...          ...      ...      ...      ...      ...       ...       ...   \n",
       "195191        -4        1        1     <NA>       -4        -4         4   \n",
       "195192        -4        1        1     <NA>       -4        -4         5   \n",
       "195193        -4        1        1     <NA>       -4        -4         5   \n",
       "195194        -4        1        1     <NA>       -4        -4         5   \n",
       "195195        -4       -4       -4     <NA>       -4        -4        -4   \n",
       "\n",
       "        MMSEORLO  PENTAGON  NACCMMSE  ...  CRAFTCUE  MINTTOTS MINTTOTW  \\\n",
       "0             -4        -4        -4  ...         0        32       32   \n",
       "1             -4        -4        -4  ...         1        31       31   \n",
       "2             -4        -4        -4  ...         0        32       32   \n",
       "3             -4        -4        -4  ...         1        20       15   \n",
       "4             -4        -4        -4  ...         0        30       30   \n",
       "...          ...       ...       ...  ...       ...       ...      ...   \n",
       "195191         5         0        26  ...        -4        -4       -4   \n",
       "195192         5        -4        28  ...        -4        -4       -4   \n",
       "195193         4        -4        28  ...        -4        -4       -4   \n",
       "195194         3         1        27  ...        -4        -4       -4   \n",
       "195195        -4        -4        -4  ...         0        32       32   \n",
       "\n",
       "        MINTSCNG  MINTSCNC  MINTPCNG  MINTPCNC  NACCC2  has_MMSE  has_MOCA  \n",
       "0              0        88         0        88       0     False      True  \n",
       "1              0        88         1         1       0     False      True  \n",
       "2              0        88         0        88       0     False      True  \n",
       "3             17         5        12         4       0     False      True  \n",
       "4              2         0         2         2       0     False      True  \n",
       "...          ...       ...       ...       ...     ...       ...       ...  \n",
       "195191        -4        -4        -4        -4      -4      True     False  \n",
       "195192        -4        -4        -4        -4      -4      True     False  \n",
       "195193        -4        -4        -4        -4      -4      True     False  \n",
       "195194        -4        -4        -4        -4      -4      True     False  \n",
       "195195         0        88         0        88       0     False      True  \n",
       "\n",
       "[195196 rows x 98 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMSECOMP</th>\n",
       "      <th>MMSELOC</th>\n",
       "      <th>MMSELAN</th>\n",
       "      <th>MMSELANX</th>\n",
       "      <th>MMSEVIS</th>\n",
       "      <th>MMSEHEAR</th>\n",
       "      <th>MMSEORDA</th>\n",
       "      <th>MMSEORLO</th>\n",
       "      <th>PENTAGON</th>\n",
       "      <th>NACCMMSE</th>\n",
       "      <th>...</th>\n",
       "      <th>CRAFTCUE</th>\n",
       "      <th>MINTTOTS</th>\n",
       "      <th>MINTTOTW</th>\n",
       "      <th>MINTSCNG</th>\n",
       "      <th>MINTSCNC</th>\n",
       "      <th>MINTPCNG</th>\n",
       "      <th>MINTPCNC</th>\n",
       "      <th>NACCC2</th>\n",
       "      <th>has_MMSE</th>\n",
       "      <th>has_MOCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195191</th>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195192</th>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-4</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195193</th>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195194</th>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195195</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195196 rows × 98 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "      Column  Valid_Data_Count  Percentage\n",
       "11   NPSYLAN            178784   91.592041\n",
       "28       VEG            178784   91.592041\n",
       "27   ANIMALS            178784   91.592041\n",
       "46   COGSTAT            178784   91.592041\n",
       "29    TRAILA            170585   87.391647\n",
       "..       ...               ...         ...\n",
       "14   LOGIDAY               543    0.278182\n",
       "15    LOGIYR               543    0.278182\n",
       "16  LOGIPREV               543    0.278182\n",
       "13    LOGIMO               543    0.278182\n",
       "3   MMSELANX               508    0.260251\n",
       "\n",
       "[96 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Valid_Data_Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NPSYLAN</td>\n",
       "      <td>178784</td>\n",
       "      <td>91.592041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>VEG</td>\n",
       "      <td>178784</td>\n",
       "      <td>91.592041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ANIMALS</td>\n",
       "      <td>178784</td>\n",
       "      <td>91.592041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>COGSTAT</td>\n",
       "      <td>178784</td>\n",
       "      <td>91.592041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TRAILA</td>\n",
       "      <td>170585</td>\n",
       "      <td>87.391647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LOGIDAY</td>\n",
       "      <td>543</td>\n",
       "      <td>0.278182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LOGIYR</td>\n",
       "      <td>543</td>\n",
       "      <td>0.278182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LOGIPREV</td>\n",
       "      <td>543</td>\n",
       "      <td>0.278182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LOGIMO</td>\n",
       "      <td>543</td>\n",
       "      <td>0.278182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMSELANX</td>\n",
       "      <td>508</td>\n",
       "      <td>0.260251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:14:25.810917Z",
     "start_time": "2025-12-09T21:14:25.808445Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into MMSE-only and MOCA-only (XOR) and save\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:14:26.864042Z",
     "start_time": "2025-12-09T21:14:25.990130Z"
    }
   },
   "source": [
    "# Keep rows where exactly one of has_MMSE / has_MOCA is True (XOR)\n",
    "xor_mask = cleaned[\"has_MMSE\"] ^ cleaned[\"has_MOCA\"]\n",
    "filtered = cleaned.loc[xor_mask].copy()\n",
    "\n",
    "# Split into two sets\n",
    "df_mmse_only = filtered.loc[filtered[\"has_MMSE\"]].copy()\n",
    "df_moca_only = filtered.loc[filtered[\"has_MOCA\"]].copy()\n",
    "\n",
    "# Save\n",
    "mmse_only_path = out_dir / 'mmse_only.parquet'\n",
    "moca_only_path = out_dir / 'moca_only.parquet'\n",
    "df_mmse_only.to_parquet(mmse_only_path, index=False)\n",
    "df_moca_only.to_parquet(moca_only_path, index=False)\n",
    "\n",
    "print(\n",
    "    f\"Saved MMSE-only rows: {len(df_mmse_only)} to {mmse_only_path}\\n\"\n",
    "    f\"Saved MOCA-only rows: {len(df_moca_only)} to {moca_only_path}\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved MMSE-only rows: 102981 to ..\\..\\outputs\\uds_extraction\\mmse_only.parquet\n",
      "Saved MOCA-only rows: 67601 to ..\\..\\outputs\\uds_extraction\\moca_only.parquet\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:14:26.987972Z",
     "start_time": "2025-12-09T21:14:26.984740Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation analysis for MMSE-only and MOCA-only sets\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:14:38.047472Z",
     "start_time": "2025-12-09T21:14:26.995403Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _prepare_numeric(df: pd.DataFrame, drop_cols=None) -> pd.DataFrame:\n",
    "    drop_cols = set(drop_cols or [])\n",
    "    # Select numeric columns only\n",
    "    num = df.select_dtypes(include=[\"number\"]).copy()\n",
    "    # Drop known indicator/ID columns if present\n",
    "    for col in [\"has_MMSE\", \"has_MOCA\"]:\n",
    "        if col in num.columns:\n",
    "            drop_cols.add(col)\n",
    "    num = num.drop(columns=[c for c in drop_cols if c in num.columns], errors=\"ignore\")\n",
    "    # Drop columns that are all NA or constant\n",
    "    non_na = num.dropna(axis=1, how=\"all\")\n",
    "    nunique = non_na.nunique(dropna=True)\n",
    "    non_constant = non_na.loc[:, nunique > 1]\n",
    "    # Further drop near-zero-variance (NZV) columns to aid factor convergence\n",
    "    # Criteria: very small variance OR one level dominates (>= 99% same value)\n",
    "    if non_constant.shape[1] == 0:\n",
    "        return non_constant\n",
    "    variances = non_constant.var(ddof=0)\n",
    "    var_mask = variances > 1e-6\n",
    "    # Dominant level frequency\n",
    "    freq_mask = []\n",
    "    for c in non_constant.columns:\n",
    "        vc = non_constant[c].value_counts(normalize=True, dropna=True)\n",
    "        max_prop = float(vc.iloc[0]) if len(vc) else 1.0\n",
    "        freq_mask.append(max_prop < 0.99)\n",
    "    freq_mask = pd.Series(freq_mask, index=non_constant.columns)\n",
    "    keep_mask = var_mask & freq_mask\n",
    "    nzv_filtered = non_constant.loc[:, keep_mask]\n",
    "    return nzv_filtered\n",
    "\n",
    "def compute_and_save_correlations(df: pd.DataFrame, label: str, out_dir: Path,\n",
    "                                  methods=(\"pearson\", \"spearman\"),\n",
    "                                  plot=PLOT_HEATMAP) -> None:\n",
    "    data = _prepare_numeric(df)\n",
    "    if data.shape[1] < 2:\n",
    "        print(f\"[{label}] Not enough numeric columns for correlation (found {data.shape[1]}). Skipping.\")\n",
    "        return\n",
    "    for method in methods:\n",
    "        corr = data.corr(method=method)\n",
    "        out_csv = out_dir / f\"corr_{label}_{method}.csv\"\n",
    "        corr.to_csv(out_csv)\n",
    "        print(f\"[{label}] Saved {method} correlation matrix to {out_csv}\")\n",
    "        if plot:\n",
    "            plt.figure(figsize=(max(8, min(20, 0.35 * corr.shape[1])),\n",
    "                               max(6, min(20, 0.35 * corr.shape[0]))))\n",
    "            sns.heatmap(corr, cmap=\"vlag\", center=0, square=True,\n",
    "                        cbar_kws={\"shrink\": 0.6}, linewidths=0.3)\n",
    "            plt.title(f\"{label.upper()} — {method.title()} correlation\")\n",
    "            plt.tight_layout()\n",
    "            img_path = out_dir / f\"corr_{label}_{method}.png\"\n",
    "            plt.savefig(img_path, dpi=200)\n",
    "            plt.close()\n",
    "            print(f\"[{label}] Saved {method} correlation heatmap to {img_path}\")\n",
    "\n",
    "# Run for each set separately\n",
    "compute_and_save_correlations(df_mmse_only, label=\"mmse_only\", out_dir=out_dir)\n",
    "compute_and_save_correlations(df_moca_only, label=\"moca_only\", out_dir=out_dir)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mmse_only] Saved pearson correlation matrix to ..\\..\\outputs\\uds_extraction\\corr_mmse_only_pearson.csv\n",
      "[mmse_only] Saved pearson correlation heatmap to ..\\..\\outputs\\uds_extraction\\corr_mmse_only_pearson.png\n",
      "[mmse_only] Saved spearman correlation matrix to ..\\..\\outputs\\uds_extraction\\corr_mmse_only_spearman.csv\n",
      "[mmse_only] Saved spearman correlation heatmap to ..\\..\\outputs\\uds_extraction\\corr_mmse_only_spearman.png\n",
      "[moca_only] Saved pearson correlation matrix to ..\\..\\outputs\\uds_extraction\\corr_moca_only_pearson.csv\n",
      "[moca_only] Saved pearson correlation heatmap to ..\\..\\outputs\\uds_extraction\\corr_moca_only_pearson.png\n",
      "[moca_only] Saved spearman correlation matrix to ..\\..\\outputs\\uds_extraction\\corr_moca_only_spearman.csv\n",
      "[moca_only] Saved spearman correlation heatmap to ..\\..\\outputs\\uds_extraction\\corr_moca_only_spearman.png\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:14:38.181012Z",
     "start_time": "2025-12-09T21:14:38.178249Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation filter and Exploratory Factor Analysis (EFA)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:20:20.599650Z",
     "start_time": "2025-12-09T21:14:38.187712Z"
    }
   },
   "source": [
    "from typing import List, Tuple, Dict\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "def _missing_rate_per_column(df: pd.DataFrame) -> pd.Series:\n",
    "    return df.isna().mean()\n",
    "\n",
    "def correlation_filter(df: pd.DataFrame,\n",
    "                       method: str = \"spearman\",\n",
    "                       threshold: float = 0.95,\n",
    "                       prefer_keep: Tuple[str, ...] = (),\n",
    "                       drop_cols: Tuple[str, ...] = ()) -> Tuple[pd.DataFrame, List[str], pd.DataFrame]:\n",
    "    \"\"\"Filter out one variable from any pair with |corr| >= threshold.\n",
    "\n",
    "    Tie-breaker rules:\n",
    "      1) Keep variables listed in prefer_keep if involved in a tie.\n",
    "      2) Otherwise drop the one with higher missingness rate.\n",
    "      3) If equal, drop the one that is later alphabetically.\n",
    "\n",
    "    Returns: (filtered_df, dropped_columns, corr_matrix_of_kept)\n",
    "    \"\"\"\n",
    "    data = _prepare_numeric(df, drop_cols=drop_cols)\n",
    "    if data.shape[1] < 2:\n",
    "        return data, [], data.corr(method=method)\n",
    "\n",
    "    corr = data.corr(method=method).abs()\n",
    "    np.fill_diagonal(corr.values, 0.0)\n",
    "    miss = _missing_rate_per_column(data)\n",
    "\n",
    "    to_drop: set = set()\n",
    "    keep_set: set = set(prefer_keep)\n",
    "    cols = list(data.columns)\n",
    "\n",
    "    # Create list of pairs above threshold\n",
    "    pairs: List[Tuple[str, str, float]] = []\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            r = corr.iloc[i, j]\n",
    "            if r >= threshold:\n",
    "                pairs.append((cols[i], cols[j], r))\n",
    "\n",
    "    # Sort pairs by strength descending so we handle strongest first\n",
    "    pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    for a, b, _ in pairs:\n",
    "        if a in to_drop or b in to_drop:\n",
    "            continue\n",
    "        # Decide which to drop\n",
    "        if a in keep_set and b in keep_set:\n",
    "            # both preferred, fall through to missingness\n",
    "            pass\n",
    "        elif a in keep_set:\n",
    "            to_drop.add(b)\n",
    "            continue\n",
    "        elif b in keep_set:\n",
    "            to_drop.add(a)\n",
    "            continue\n",
    "\n",
    "        ma = float(miss.get(a, 0.0))\n",
    "        mb = float(miss.get(b, 0.0))\n",
    "        if ma > mb:\n",
    "            to_drop.add(a)\n",
    "        elif mb > ma:\n",
    "            to_drop.add(b)\n",
    "        else:\n",
    "            # Alphabetical tiebreaker: drop later\n",
    "            to_drop.add(max(a, b))\n",
    "\n",
    "    kept_cols = [c for c in cols if c not in to_drop]\n",
    "    filtered = data[kept_cols].copy()\n",
    "    corr_kept = filtered.corr(method=method)\n",
    "    return filtered, sorted(list(to_drop)), corr_kept\n",
    "\n",
    "def _standardize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (df - df.mean()) / df.std(ddof=0)\n",
    "\n",
    "def _eigenvalues_from_corr(df: pd.DataFrame) -> np.ndarray:\n",
    "    c = df.corr(method=\"pearson\").fillna(0)\n",
    "    vals, _ = np.linalg.eigh(c.values)\n",
    "    return np.sort(vals)[::-1]\n",
    "\n",
    "def varimax(Phi: np.ndarray, gamma: float = 1.0, q: int = 20, tol: float = 1e-6) -> np.ndarray:\n",
    "    \"\"\"Varimax rotation of loadings matrix Phi (features x factors).\"\"\"\n",
    "    p, k = Phi.shape\n",
    "    R = np.eye(k)\n",
    "    d = 0\n",
    "    for i in range(q):\n",
    "        d_old = d\n",
    "        Lambda = Phi @ R\n",
    "        u, s, vh = np.linalg.svd(Phi.T @ (Lambda**3 - (gamma / p) * (Lambda @ np.diag(np.diag(Lambda.T @ Lambda)))))\n",
    "        R = u @ vh\n",
    "        d = s.sum()\n",
    "        if d_old != 0 and d / d_old < 1 + tol:\n",
    "            break\n",
    "    return Phi @ R\n",
    "\n",
    "def run_efa(df: pd.DataFrame,\n",
    "            label: str,\n",
    "            out_dir: Path,\n",
    "            rotation: str = \"varimax\",\n",
    "            kaiser: bool = True,\n",
    "            n_factors: int = None) -> Dict[str, object]:\n",
    "    \"\"\"Run EFA on standardized numeric data with listwise deletion.\n",
    "    Chooses number of factors by Kaiser criterion if n_factors is None and kaiser is True.\n",
    "    Saves artifacts to out_dir with prefix 'efa_{label}_*'.\n",
    "    \"\"\"\n",
    "    X = _prepare_numeric(df)\n",
    "    # Listwise deletion\n",
    "    X = X.dropna(axis=0, how=\"any\")\n",
    "    if X.shape[1] < 2 or X.shape[0] < 10:\n",
    "        print(f\"[{label}] Not enough data for EFA. Observations={X.shape[0]}, Vars={X.shape[1]}\")\n",
    "        return {}\n",
    "\n",
    "    # Standardize\n",
    "    Z = _standardize(X)\n",
    "\n",
    "    # Determine number of factors\n",
    "    if n_factors is None:\n",
    "        eigvals = _eigenvalues_from_corr(Z)\n",
    "        if kaiser:\n",
    "            n_factors = int((eigvals > 1.0).sum())\n",
    "        if not kaiser or n_factors < 1:\n",
    "            n_factors = max(1, min(6, X.shape[1] // 3))\n",
    "    # Scree plot\n",
    "    eigvals = _eigenvalues_from_corr(Z)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(range(1, len(eigvals)+1), eigvals, marker='o')\n",
    "    plt.xlabel('Component')\n",
    "    plt.ylabel('Eigenvalue')\n",
    "    plt.title(f'{label.upper()} Scree Plot')\n",
    "    plt.tight_layout()\n",
    "    scree_path = out_dir / f'efa_{label}_scree.png'\n",
    "    plt.savefig(scree_path, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"[{label}] Saved scree plot to {scree_path}\")\n",
    "\n",
    "    # Fit FactorAnalysis (ML) and rotate\n",
    "    fa = FactorAnalysis(n_components=n_factors, rotation=None)\n",
    "    fa.fit(Z.values)\n",
    "    loadings = fa.components_.T  # features x factors\n",
    "    if rotation == \"varimax\":\n",
    "        loadings = varimax(loadings)\n",
    "\n",
    "    # Summaries\n",
    "    features = list(Z.columns)\n",
    "    loadings_df = pd.DataFrame(loadings, index=features, columns=[f\"F{i+1}\" for i in range(loadings.shape[1])])\n",
    "    uniqueness = getattr(fa, 'noise_variance_', np.maximum(0.0, 1.0 - (loadings**2).sum(axis=1)))\n",
    "    communalities = 1.0 - uniqueness\n",
    "    comm_df = pd.DataFrame({\"communality\": communalities, \"uniqueness\": uniqueness}, index=features)\n",
    "\n",
    "    # Save artifacts\n",
    "    loadings_csv = out_dir / f\"efa_{label}_loadings.csv\"\n",
    "    loadings_df.to_csv(loadings_csv)\n",
    "    print(f\"[{label}] Saved loadings to {loadings_csv}\")\n",
    "\n",
    "    comm_csv = out_dir / f\"efa_{label}_communalities.csv\"\n",
    "    comm_df.to_csv(comm_csv)\n",
    "    print(f\"[{label}] Saved communalities/uniqueness to {comm_csv}\")\n",
    "\n",
    "    # Heatmap of loadings\n",
    "    plt.figure(figsize=(max(6, 0.5 * loadings_df.shape[1] + 4), max(6, 0.25 * loadings_df.shape[0] + 2)))\n",
    "    sns.heatmap(loadings_df, cmap=\"coolwarm\", center=0, cbar_kws={\"shrink\": 0.6})\n",
    "    plt.title(f\"{label.upper()} Factor Loadings ({n_factors} factors)\")\n",
    "    plt.tight_layout()\n",
    "    loadings_png = out_dir / f\"efa_{label}_loadings.png\"\n",
    "    plt.savefig(loadings_png, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"[{label}] Saved loadings heatmap to {loadings_png}\")\n",
    "\n",
    "    return {\n",
    "        \"n_factors\": n_factors,\n",
    "        \"loadings\": loadings_df,\n",
    "        \"communalities\": comm_df,\n",
    "        \"scree\": scree_path,\n",
    "    }\n",
    "\n",
    "# Apply correlation filter with confirmed parameters, then EFA\n",
    "CF_METHOD = \"spearman\"\n",
    "CF_THRESHOLD = 0.95\n",
    "\n",
    "def run_correlation_filter_and_efa(df: pd.DataFrame, label: str):\n",
    "    # Correlation filter\n",
    "    filtered, dropped, corr_kept = correlation_filter(df, method=CF_METHOD, threshold=CF_THRESHOLD)\n",
    "    # Save correlation after filtering\n",
    "    out_csv = out_dir / f\"corr_{label}_filtered_{CF_METHOD}.csv\"\n",
    "    corr_kept.to_csv(out_csv)\n",
    "    print(f\"[{label}] Saved filtered correlation matrix to {out_csv}\")\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(max(8, min(20, 0.35 * corr_kept.shape[1])), max(6, min(20, 0.35 * corr_kept.shape[0]))))\n",
    "    sns.heatmap(corr_kept, cmap=\"vlag\", center=0, square=True, cbar_kws={\"shrink\": 0.6}, linewidths=0.3)\n",
    "    plt.title(f\"{label.upper()} — filtered ({CF_METHOD}) correlation\")\n",
    "    plt.tight_layout()\n",
    "    img_path = out_dir / f\"corr_{label}_filtered_{CF_METHOD}.png\"\n",
    "    plt.savefig(img_path, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"[{label}] Saved filtered correlation heatmap to {img_path}\")\n",
    "    if dropped:\n",
    "        print(f\"[{label}] Dropped due to high correlation (|r|>={CF_THRESHOLD}): {', '.join(dropped)}\")\n",
    "\n",
    "    # EFA on filtered data\n",
    "    run_efa(filtered, label=label, out_dir=out_dir, rotation=\"varimax\", kaiser=True, n_factors=None)\n",
    "\n",
    "run_correlation_filter_and_efa(df_mmse_only, label=\"mmse_only\")\n",
    "run_correlation_filter_and_efa(df_moca_only, label=\"moca_only\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mmse_only] Saved filtered correlation matrix to ..\\..\\outputs\\uds_extraction\\corr_mmse_only_filtered_spearman.csv\n",
      "[mmse_only] Saved filtered correlation heatmap to ..\\..\\outputs\\uds_extraction\\corr_mmse_only_filtered_spearman.png\n",
      "[mmse_only] Dropped due to high correlation (|r|>=0.95): DIGIBLEN, MMSEHEAR, MMSEVIS, NPSYLAN, UDSBENTC, UDSBENTD, UDSVERFC, UDSVERFN, UDSVERLC, UDSVERLN, UDSVERLR, UDSVERNF, UDSVERTE, UDSVERTI, UDSVERTN\n",
      "[mmse_only] Saved scree plot to ..\\..\\outputs\\uds_extraction\\efa_mmse_only_scree.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\curti\\anaconda3\\envs\\Crary_Lab_Research\\Lib\\site-packages\\sklearn\\decomposition\\_factor_analysis.py:296: ConvergenceWarning: FactorAnalysis did not converge. You might want to increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mmse_only] Saved loadings to ..\\..\\outputs\\uds_extraction\\efa_mmse_only_loadings.csv\n",
      "[mmse_only] Saved communalities/uniqueness to ..\\..\\outputs\\uds_extraction\\efa_mmse_only_communalities.csv\n",
      "[mmse_only] Saved loadings heatmap to ..\\..\\outputs\\uds_extraction\\efa_mmse_only_loadings.png\n",
      "[moca_only] Saved filtered correlation matrix to ..\\..\\outputs\\uds_extraction\\corr_moca_only_filtered_spearman.csv\n",
      "[moca_only] Saved filtered correlation heatmap to ..\\..\\outputs\\uds_extraction\\corr_moca_only_filtered_spearman.png\n",
      "[moca_only] Dropped due to high correlation (|r|>=0.95): CRAFTDVR, CRAFTVRS, MOCAREAS, NACCMOCA\n",
      "[moca_only] Saved scree plot to ..\\..\\outputs\\uds_extraction\\efa_moca_only_scree.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\curti\\anaconda3\\envs\\Crary_Lab_Research\\Lib\\site-packages\\sklearn\\decomposition\\_factor_analysis.py:296: ConvergenceWarning: FactorAnalysis did not converge. You might want to increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[moca_only] Saved loadings to ..\\..\\outputs\\uds_extraction\\efa_moca_only_loadings.csv\n",
      "[moca_only] Saved communalities/uniqueness to ..\\..\\outputs\\uds_extraction\\efa_moca_only_communalities.csv\n",
      "[moca_only] Saved loadings heatmap to ..\\..\\outputs\\uds_extraction\\efa_moca_only_loadings.png\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:20:20.785415Z",
     "start_time": "2025-12-09T21:20:20.781930Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

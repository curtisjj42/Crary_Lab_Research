{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDS Table Extraction and Dataset Cleaning (Clean Notebook)\n",
    "\n",
    "This notebook focuses on extracting the C1/C2 Neuropsych Battery variable catalog from the UDS PDF and aligning the investigator CSV to those variables.\n",
    "\n",
    "Outputs saved to the configured output directory include:\n",
    "- `variable_catalog.csv`\n",
    "- `cleaned_subset.parquet` (only catalog variables)\n",
    "- `availability_summary.csv` (column-wise non-missing counts)\n",
    "- `stats.txt` (empty-rows summary)\n",
    "- Optional: `availability_heatmap.png`\n",
    "\n",
    "Requirements: `pandas`, `pdfplumber`, `matplotlib`, `seaborn` (for optional heatmap).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T20:04:07.344836Z",
     "start_time": "2025-12-05T20:04:07.337036Z"
    }
   },
   "source": [
    "# Parameters\n",
    "CSV_PATH = '../../data-files/investigator_nacc67.csv'\n",
    "PDF_PATH = '../../data-files/rdd_uds.pdf'\n",
    "PAGE_RANGE = (23, 27)  # inclusive zero-based pages for C1/C2 tables\n",
    "OUT_DIR = '../../outputs/uds_extraction'\n",
    "MMSE_COLS = ['NACCMMSE']  # extend if needed\n",
    "MOCA_COLS = ['NACCMOCA']  # extend if needed\n",
    "PLOT_HEATMAP = True\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T20:04:21.777797Z",
     "start_time": "2025-12-05T20:04:21.219307Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src.data.uds_extraction import (\n",
    "    build_variable_catalog,\n",
    "    load_nacc_csv,\n",
    "    align_dataset_to_catalog,\n",
    "    compute_empty_rows_mask,\n",
    "    plot_availability_heatmap,\n",
    ")\n",
    "\n",
    "out_dir = Path(OUT_DIR)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_dir.as_posix()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../outputs/uds_extraction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Build variable catalog from PDF\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T20:05:04.987460Z",
     "start_time": "2025-12-05T20:05:03.435695Z"
    }
   },
   "source": [
    "catalog = build_variable_catalog(PDF_PATH, PAGE_RANGE)\n",
    "catalog_path = out_dir / 'variable_catalog.csv'\n",
    "catalog.to_csv(catalog_path, index=False)\n",
    "catalog.head(10)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                      form_field variable_name  \\\n",
       "0                                             C1      MMSECOMP   \n",
       "1  C1 Neuropsychological Battery\\nSummary Scores       MMSELOC   \n",
       "2                                             C1       MMSELAN   \n",
       "3  C1 Neuropsychological Battery\\nSummary Scores      MMSELANX   \n",
       "4                                             C1       MMSEVIS   \n",
       "5  C1 Neuropsychological Battery\\nSummary Scores      MMSEHEAR   \n",
       "6                                             C1      MMSEORDA   \n",
       "7  C1 Neuropsychological Battery\\nSummary Scores      MMSEORLO   \n",
       "8                                             C1      PENTAGON   \n",
       "9  C1 Neuropsychological Battery\\nSummary Scores      NACCMMSE   \n",
       "\n",
       "                                               label  source_page  \n",
       "0                Was any part of the MMSE completed?           26  \n",
       "1                    Administration of the MMSE was:           27  \n",
       "2                    Language of MMSE administration           28  \n",
       "3  Language of MMSE administration —\\nOther (spec...           29  \n",
       "4  Subject was unable to complete one or\\nmore se...           30  \n",
       "5  Subject was unable to complete one or\\nmore se...           31  \n",
       "6                  Orientation subscale score — Time           32  \n",
       "7                 Orientation subscale score — Place           33  \n",
       "8               Intersecting pentagon subscale score           34  \n",
       "9                 Total MMSE score (using D-L-R-O-W)           35  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form_field</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>label</th>\n",
       "      <th>source_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1</td>\n",
       "      <td>MMSECOMP</td>\n",
       "      <td>Was any part of the MMSE completed?</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1 Neuropsychological Battery\\nSummary Scores</td>\n",
       "      <td>MMSELOC</td>\n",
       "      <td>Administration of the MMSE was:</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1</td>\n",
       "      <td>MMSELAN</td>\n",
       "      <td>Language of MMSE administration</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1 Neuropsychological Battery\\nSummary Scores</td>\n",
       "      <td>MMSELANX</td>\n",
       "      <td>Language of MMSE administration —\\nOther (spec...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1</td>\n",
       "      <td>MMSEVIS</td>\n",
       "      <td>Subject was unable to complete one or\\nmore se...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C1 Neuropsychological Battery\\nSummary Scores</td>\n",
       "      <td>MMSEHEAR</td>\n",
       "      <td>Subject was unable to complete one or\\nmore se...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C1</td>\n",
       "      <td>MMSEORDA</td>\n",
       "      <td>Orientation subscale score — Time</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C1 Neuropsychological Battery\\nSummary Scores</td>\n",
       "      <td>MMSEORLO</td>\n",
       "      <td>Orientation subscale score — Place</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C1</td>\n",
       "      <td>PENTAGON</td>\n",
       "      <td>Intersecting pentagon subscale score</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C1 Neuropsychological Battery\\nSummary Scores</td>\n",
       "      <td>NACCMMSE</td>\n",
       "      <td>Total MMSE score (using D-L-R-O-W)</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Load CSV and align to catalog\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T20:06:27.884700Z",
     "start_time": "2025-12-05T20:05:12.636870Z"
    }
   },
   "source": [
    "df = load_nacc_csv(CSV_PATH)\n",
    "cleaned, availability = align_dataset_to_catalog(\n",
    "    df, catalog, mmse_cols=MMSE_COLS, moca_cols=MOCA_COLS\n",
    ")\n",
    "cleaned_path = out_dir / 'cleaned_subset.parquet'\n",
    "availability_path = out_dir / 'availability_summary.csv'\n",
    "cleaned.to_parquet(cleaned_path, index=False)\n",
    "availability.to_csv(availability_path, index=False)\n",
    "cleaned.shape, availability.shape\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\curti\\PycharmProjects\\Crary_Lab_Research\\src\\data\\uds_extraction.py:226: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(path)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      5\u001B[39m cleaned_path = out_dir / \u001B[33m'\u001B[39m\u001B[33mcleaned_subset.parquet\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m      6\u001B[39m availability_path = out_dir / \u001B[33m'\u001B[39m\u001B[33mavailability_summary.csv\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m \u001B[43mcleaned\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_parquet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcleaned_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m      8\u001B[39m availability.to_csv(availability_path, index=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m      9\u001B[39m cleaned.shape, availability.shape\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\Crary_Lab_Research\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001B[39m, in \u001B[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    327\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) > num_allow_args:\n\u001B[32m    328\u001B[39m     warnings.warn(\n\u001B[32m    329\u001B[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001B[32m    330\u001B[39m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[32m    331\u001B[39m         stacklevel=find_stack_level(),\n\u001B[32m    332\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m333\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\Crary_Lab_Research\\Lib\\site-packages\\pandas\\core\\frame.py:3124\u001B[39m, in \u001B[36mDataFrame.to_parquet\u001B[39m\u001B[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001B[39m\n\u001B[32m   3043\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   3044\u001B[39m \u001B[33;03mWrite a DataFrame to the binary parquet format.\u001B[39;00m\n\u001B[32m   3045\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   3120\u001B[39m \u001B[33;03m>>> content = f.read()\u001B[39;00m\n\u001B[32m   3121\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   3122\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mio\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mparquet\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m to_parquet\n\u001B[32m-> \u001B[39m\u001B[32m3124\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mto_parquet\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3125\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   3126\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3127\u001B[39m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3128\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3129\u001B[39m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3130\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpartition_cols\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpartition_cols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3131\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3132\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3133\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\Crary_Lab_Research\\Lib\\site-packages\\pandas\\io\\parquet.py:478\u001B[39m, in \u001B[36mto_parquet\u001B[39m\u001B[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001B[39m\n\u001B[32m    476\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(partition_cols, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    477\u001B[39m     partition_cols = [partition_cols]\n\u001B[32m--> \u001B[39m\u001B[32m478\u001B[39m impl = \u001B[43mget_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    480\u001B[39m path_or_buf: FilePath | WriteBuffer[\u001B[38;5;28mbytes\u001B[39m] = io.BytesIO() \u001B[38;5;28;01mif\u001B[39;00m path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m path\n\u001B[32m    482\u001B[39m impl.write(\n\u001B[32m    483\u001B[39m     df,\n\u001B[32m    484\u001B[39m     path_or_buf,\n\u001B[32m   (...)\u001B[39m\u001B[32m    490\u001B[39m     **kwargs,\n\u001B[32m    491\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\Crary_Lab_Research\\Lib\\site-packages\\pandas\\io\\parquet.py:68\u001B[39m, in \u001B[36mget_engine\u001B[39m\u001B[34m(engine)\u001B[39m\n\u001B[32m     65\u001B[39m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[32m     66\u001B[39m             error_msgs += \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m - \u001B[39m\u001B[33m\"\u001B[39m + \u001B[38;5;28mstr\u001B[39m(err)\n\u001B[32m---> \u001B[39m\u001B[32m68\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[32m     69\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mUnable to find a usable engine; \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     70\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mtried using: \u001B[39m\u001B[33m'\u001B[39m\u001B[33mpyarrow\u001B[39m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m\u001B[33mfastparquet\u001B[39m\u001B[33m'\u001B[39m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     71\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mA suitable version of \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     72\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mpyarrow or fastparquet is required for parquet \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     73\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33msupport.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     74\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mTrying to import the above resulted in these errors:\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     75\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror_msgs\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     76\u001B[39m     )\n\u001B[32m     78\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m engine == \u001B[33m\"\u001B[39m\u001B[33mpyarrow\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m     79\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m PyArrowImpl()\n",
      "\u001B[31mImportError\u001B[39m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Empty-rows statistics and optional heatmap\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_mask = compute_empty_rows_mask(cleaned)\n",
    "stats_txt = (\n",
    "    f'Rows total: {len(cleaned)}\\n'\n",
    "    f'Completely empty (all -4/NaN): {int(empty_mask.sum())}\\n'\n",
    "    f'With some data: {int((~empty_mask).sum())}\\n'\n",
    ")\n",
    "(out_dir / 'stats.txt').write_text(stats_txt)\n",
    "print(stats_txt)\n",
    "if PLOT_HEATMAP:\n",
    "    plot_availability_heatmap(cleaned, out_path=str(out_dir / 'availability_heatmap.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Quick previews\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cleaned.head())\n",
    "display(availability.head())\n",
    "# End of notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Look at a few sample rows with some data\n",
    "rows_with_data = df_neither[~completely_empty]\n",
    "\n",
    "if len(rows_with_data) > 0:\n",
    "    print(f\"\\nSample of rows with some data (showing first 5):\")\n",
    "    print(rows_with_data.head())\n",
    "    \n",
    "    # Show which columns have data in these sample rows\n",
    "    print(\"\\nNon-empty values in first sample row:\")\n",
    "    first_row = rows_with_data.iloc[0]\n",
    "    for col in first_row.index:\n",
    "        if col not in ['has_MMSE', 'has_MOCA'] and pd.notna(first_row[col]) and first_row[col] != -4:\n",
    "            print(f\"  {col}: {first_row[col]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
